# Instagram Scraper GraphQL Completo - Sistema Avanzado con Base de Datos

Sistema de scraping avanzado de Instagram que usa GraphQL API directa para extraer datos completos de usuarios, incluyendo posts e historias destacadas, con base de datos SQLite para evitar re-scrapear perfiles ya completos.

## üöÄ Inicio R√°pido

1. **Instalar dependencias:**
   ```bash
   pip install selenium webdriver-manager requests
   ```

2. **Agregar usuarios a la base de datos:**
   ```bash
   python scraper_perfil.py
   # Seleccionar opci√≥n 2: Agregar usuarios a BD
   # Ingresar usernames separados por comas: leomessi,cristiano,nasa
   ```

3. **Scrapear usuarios:**
   ```bash
   python scraper_perfil.py
   # Seleccionar opci√≥n 1: Scrapear usuarios pendientes
   ```

## üìÅ Archivos del Proyecto

### üéØ **Archivos Principales (Solo 4 esenciales)**
- **`scraper_perfil.py`** - üÜï Scraper de perfiles completo con posts e highlights
- **`database.py`** - M√≥dulo de base de datos SQLite  
- **`login.py`** - Sistema de login interactivo (EL √öNICO archivo de login)
- **`config.py`** - Configuraci√≥n del proyecto

## üÜï Caracter√≠sticas del Nuevo Scraper GraphQL

### ‚úÖ **Datos Completos Extra√≠dos**
- **Informaci√≥n b√°sica**: Seguidores, siguiendo, biograf√≠a, etc.
- **Posts**: Thumbnails, likes, comentarios, tipo (foto/video)
- **Highlights**: T√≠tulos, thumbnails de historias destacadas
- **Estad√≠sticas**: Promedios, totales, an√°lisis autom√°tico


### üîí **Variables Hardcodeadas vs Din√°micas**

El scraper utiliza una combinaci√≥n de variables hardcodeadas y din√°micas para las solicitudes GraphQL. Aqu√≠ se explica cada tipo:

#### **üìä Resumen de Criticidad**

| Tipo | Riesgo | Estado | Acci√≥n |
|------|--------|--------|--------|
| üî¥ **Tokens de autenticaci√≥n** | Alto | ‚úÖ Din√°micos | Funcionan correctamente |
| üü° **Hashes de sesi√≥n** | Medio | ‚ö†Ô∏è Hardcodeados | Actualizar si fallan |
| üü¢ **Headers HTTP est√°ndar** | Bajo | ‚úÖ Hardcodeados | No requieren cambios |
| üîí **Doc IDs** | Alto | ‚ö†Ô∏è Hardcodeados | Monitorear cambios |

## üóÑÔ∏è Base de Datos

### Tabla `usuarios_unicos`
- `username` - Username del usuario (clave primaria)
- `perfil_inactivo` - Si el perfil no se pudo scrapear
- `nombre_persona` - Nombre real de la persona
- `categoria` - Categor√≠a si es perfil de negocio
- `perfil_privado` - Si el perfil es privado
- `cantidad_publicaciones` - N√∫mero de posts
- `cantidad_destacadas` - N√∫mero de historias destacadas
- `cantidad_seguidores` - N√∫mero de seguidores
- `cantidad_seguidos` - N√∫mero de seguidos
- `biografia` - Biograf√≠a del perfil
- `links_externos` - URL externa del perfil

### Tabla `media_urls`
- `username` - Username (clave for√°nea)
- `url_media` - URL de la imagen/video
- `tipo_media` - 'post' o 'destacada'
- `subtipo_post` - 'foto', 'reel', 'video' (solo posts)
- `cantidad_likes` - Likes del post
- `cantidad_comentarios` - Comentarios del post

## üîê Sistema de Login

**`login.py` es EL √öNICO archivo que maneja la autenticaci√≥n.** No hay otros archivos de login.

### Caracter√≠sticas:
- **Login interactivo**: Te pide usuario y contrase√±a al ejecutar
- **Contrase√±a oculta**: Usa `getpass` para ocultar la contrase√±a
- **Guardado opcional**: Puede guardar credenciales en `instagram_credentials.json`
- **Tokens autom√°ticos**: Extrae autom√°ticamente CSRF, fb_lsd, fb_dtsg
- **Manejo de 2FA**: Soporte para verificaci√≥n adicional
- **Sesi√≥n completa**: Devuelve sesi√≥n de `requests` lista para usar

### Uso program√°tico:
```python
from login import get_instagram_session

# Obtener sesi√≥n autenticada
session, tokens, username = get_instagram_session()
```

## ‚öôÔ∏è Configuraci√≥n

En `config.py`:

```python
# Configuraci√≥n de scraping
SCRAPING_CONFIG = {
    'delay_min': 2,           # Delay m√≠nimo entre requests
    'delay_max': 6,           # Delay m√°ximo entre requests
    'headless': True,         # Chrome sin ventana visible
    'force_rescrape': False,  # Si re-scrapear perfiles completos
}

# Archivos de salida
OUTPUT_CONFIG = {
    'save_csv': True,         # Si guardar archivo CSV
    'csv_file': 'instagram_profiles.csv',
    'database_file': 'instagram_data.db',
}
```

## üìä Informaci√≥n Detallada por Consola

El nuevo scraper muestra informaci√≥n completa durante la extracci√≥n:

### **Datos de Usuario**
```
‚úì Datos de usuario obtenidos:
   üë§ Nombre: @leomessi
   üìù Biograf√≠a: Futbolista profesional...
   üë• Seguidores: 500,000,000
   üë§ Siguiendo: 300
   üì∏ Posts: 1,000
   üîí Privado: No
   üè¢ Negocio: S√≠
   üìÇ Categor√≠a: Athlete
   üîó Link externo: https://example.com
```

### **Highlights**
```
‚úì 15 highlights obtenidos
   üìö Highlights encontrados:
      1. Mundial
      2. Familia
      3. Entrenamientos
      4. Viajes
      5. Celebraciones
      ... y 10 m√°s
```

### **Posts**
```
‚úì 12 posts obtenidos
   üìä Estad√≠sticas de posts:
      üì∏ Fotos: 8 | üé• Videos: 4
      ‚ù§Ô∏è Total likes: 15,000,000
      üí¨ Total comentarios: 250,000
      üìà Promedio likes: 1,250,000
```

### **Resumen Final**
```
üìã RESUMEN COMPLETO - @leomessi
==================================================
üë• Seguidores: 500,000,000
üë§ Siguiendo: 300
üì∏ Posts totales: 1,000
üì∏ Posts extra√≠dos: 12
üìö Highlights: 15
üîí Perfil privado: No
üìÇ Categor√≠a: Athlete
```

## üß† L√≥gica Inteligente

El sistema evita re-scrapear perfiles ya completos:

- **Perfil Completo**: Tiene `cantidad_seguidores`, `cantidad_seguidos` y `cantidad_publicaciones` != NULL
- **Perfil Pendiente**: Le falta alguno de los campos principales
- **Force Rescrape**: Configurar `force_rescrape = True` para re-scrapear todo

## üéØ Flujo de Trabajo Simple

1. **Agregar usuarios:**
   ```bash
   python scraper_perfil.py
   # Opci√≥n 2 ‚Üí Ingresar: leomessi,cristiano,nasa
   ```

2. **Scrapear usuarios pendientes:**
   ```bash
   python scraper_perfil.py  
   # Opci√≥n 1 ‚Üí Login interactivo ‚Üí Scraping autom√°tico
   ```

3. **Scrapear usuario espec√≠fico:**
   ```bash
   python scraper_perfil.py
   # Opci√≥n 4 ‚Üí Ingresar username ‚Üí Ver datos completos
   ```

4. **Ver estad√≠sticas:**
   ```bash
   python scraper_perfil.py
   # Opci√≥n 3 ‚Üí Ver estad√≠sticas detalladas de BD
   ```

## üîß Uso de la Base de Datos

### Con DB Browser for SQLite (Recomendado)
1. Descargar [DB Browser for SQLite](https://sqlitebrowser.org/)
2. Abrir `instagram_data.db`
3. Ver/editar datos directamente

### Consultas SQL √ötiles
```sql
-- Ver usuarios con m√°s posts extra√≠dos
SELECT u.username, u.cantidad_seguidores, COUNT(m.url_media) as posts_extraidos
FROM usuarios_unicos u
LEFT JOIN media_urls m ON u.username = m.username AND m.tipo_media = 'post'
GROUP BY u.username
ORDER BY u.cantidad_seguidores DESC;

-- Ver estad√≠sticas de engagement
SELECT u.username, 
       AVG(m.cantidad_likes) as promedio_likes,
       AVG(m.cantidad_comentarios) as promedio_comentarios
FROM usuarios_unicos u
JOIN media_urls m ON u.username = m.username
WHERE m.tipo_media = 'post'
GROUP BY u.username
ORDER BY promedio_likes DESC;

-- Ver usuarios con highlights
SELECT u.username, u.cantidad_destacadas, COUNT(m.url_media) as highlights_extraidos
FROM usuarios_unicos u
LEFT JOIN media_urls m ON u.username = m.username AND m.tipo_media = 'destacada'
GROUP BY u.username
HAVING u.cantidad_destacadas > 0
ORDER BY u.cantidad_destacadas DESC;
```

## üóÇÔ∏è Archivos que Puedes Eliminar

### üß™ **Archivos de Testing/Debug (Seguros para eliminar)**
```bash
# Scripts de debugging
rm debug_*.py
rm test_*.py
rm standalone_debug.py

# Respuestas de ejemplo
rm ejemplo_response_*.json
rm debug_response_*.json

# Herramientas de doc_id (ya no necesarias)
rm find_working_doc_ids.py
rm auto_doc_id_finder.py
rm doc_id_manager.py
rm test_doc_ids.py

# Scripts de testing espec√≠ficos
rm test_format_fix.py
rm test_doc_id_logic.py
rm test_real_user.py
rm test_new_extraction.py
rm test_data_viewer.py
rm debug_now.py
rm debug_problematic_users.py
```

### üìö **Archivos Legacy (Mantener como referencia)**
```bash
# Mantener por ahora como referencia
# scraper_user_data.py - Scraper original
# query_data_user.py - Prototipo GraphQL
```

## üîí Seguridad

- Login interactivo (no credenciales hardcodeadas)
- Contrase√±a oculta con `getpass`
- Delays inteligentes entre requests
- Manejo de 2FA y verificaciones adicionales
- Doc IDs hardcodeados (no b√∫squeda din√°mica)

## üìä Archivos Generados

- `instagram_data.db` - Base de datos SQLite principal
- `instagram_profiles.csv` - Archivo CSV (si est√° habilitado)
- `instagram_credentials.json` - Credenciales guardadas (opcional)

## ÔøΩ *o*Monitoreo y Mantenimiento**

### **üìä Indicadores de Salud del Scraper**
```python
# Ejecutar diagn√≥stico
python scraper_perfil.py
# Opci√≥n 4 ‚Üí Probar con un usuario conocido

# Se√±ales de que necesita mantenimiento:
# ‚ùå Error 400: "execution error" ‚Üí Doc IDs obsoletos
# ‚ùå Error 403: "Forbidden" ‚Üí Tokens/hashes obsoletos  
# ‚ùå Respuestas vac√≠as ‚Üí Par√°metros incorrectos
# ‚ùå Rate limiting ‚Üí Cambiar User Agent
```

### **üîÑ Frecuencia de Actualizaci√≥n Recomendada**
- **Doc IDs**: Verificar mensualmente o cuando fallen
- **Hashes de sesi√≥n**: Actualizar cada 2-3 meses
- **User Agent**: Rotar semanalmente
- **Tokens de autenticaci√≥n**: Se renuevan autom√°ticamente

### **üìà Optimizaci√≥n de Rendimiento**
```python
# Configurar delays apropiados en config.py
SCRAPING_CONFIG = {
    'delay_min': 2,    # M√≠nimo 2 segundos entre requests
    'delay_max': 6,    # M√°ximo 6 segundos para evitar detecci√≥n
}

# Monitorear tasa de √©xito
# > 90% √©xito = Configuraci√≥n √≥ptima
# < 70% √©xito = Necesita mantenimiento
```

## üö® Consideraciones

- Respetar t√©rminos de servicio de Instagram
- Uso moderado para evitar detecci√≥n
- Los tokens expiran, renovar sesi√≥n peri√≥dicamente
- **Variables hardcodeadas requieren mantenimiento peri√≥dico**
- **Doc IDs son cr√≠ticos y pueden cambiar sin aviso**
- **Monitorear regularmente la tasa de √©xito del scraper**

---

## üéâ **¬°Nuevo Sistema GraphQL Completo!**

**El nuevo `scraper_perfil.py` es la evoluci√≥n del sistema original, extrayendo datos completos de Instagram de forma r√°pida y eficiente usando la API GraphQL directa.**

### **Migraci√≥n Recomendada:**
1. ‚úÖ Usar `scraper_perfil.py` para nuevos proyectos
2. üìö Mantener `scraper_user_data.py` como referencia
3. üóëÔ∏è Eliminar archivos de testing/debug
4. üîÑ Migrar usuarios existentes ejecutando el nuevo scraper

