# Instagram Scraper GraphQL Completo - Sistema Avanzado con Base de Datos

Sistema de scraping avanzado de Instagram que usa GraphQL API directa para extraer datos completos de usuarios, incluyendo posts e historias destacadas, con base de datos SQLite para evitar re-scrapear perfiles ya completos.

## ðŸš€ Inicio RÃ¡pido

### ðŸ“¥ **Clonar desde Git**
```bash
# Clonar el repositorio
git clone <URL_DEL_REPOSITORIO>
cd instagram-scraper

# Instalar dependencias
pip install selenium webdriver-manager requests

# Inicializar base de datos con perfiles famosos
python init_database.py
```

### ðŸ  **InstalaciÃ³n Local**
1. **Instalar dependencias:**
   ```bash
   pip install selenium webdriver-manager requests
   ```

2. **Inicializar base de datos (automÃ¡tico):**
   ```bash
   python scraper_perfil.py
   # La base de datos se inicializa automÃ¡ticamente con perfiles famosos
   ```

3. **O inicializar manualmente:**
   ```bash
   python init_database.py
   ```

### ðŸŽ¯ **Comenzar Scraping**
```bash
python scraper_perfil.py
# Seleccionar opciÃ³n 1: Scrapear usuarios pendientes
# Login interactivo â†’ Scraping automÃ¡tico de perfiles famosos
```

## ðŸ“ Archivos del Proyecto

### ðŸŽ¯ **Archivos Principales (Solo 5 esenciales)**
- **`scraper_perfil.py`** - ðŸ†• Scraper de perfiles completo con posts e highlights
- **`database.py`** - MÃ³dulo de base de datos SQLite con inicializaciÃ³n automÃ¡tica
- **`login.py`** - Sistema de login interactivo (EL ÃšNICO archivo de login)
- **`config.py`** - ConfiguraciÃ³n del proyecto
- **`init_database.py`** - ðŸ†• Script de inicializaciÃ³n independiente para Git

### ðŸ”§ **Archivos de ConfiguraciÃ³n Git**
- **`.gitignore`** - Configurado para ignorar BD, credenciales y archivos temporales
- **`README.md`** - DocumentaciÃ³n completa del proyecto
- **`README_VARIABLES.md`** - DocumentaciÃ³n tÃ©cnica de variables

## ðŸ†• CaracterÃ­sticas del Nuevo Scraper GraphQL

### âœ… **Datos Completos ExtraÃ­dos**
- **InformaciÃ³n bÃ¡sica**: Seguidores, siguiendo, biografÃ­a, etc.
- **Posts**: Thumbnails, likes, comentarios, tipo (foto/video)
- **Highlights**: TÃ­tulos, thumbnails de historias destacadas
- **EstadÃ­sticas**: Promedios, totales, anÃ¡lisis automÃ¡tico


### ðŸ”’ **Variables Hardcodeadas vs DinÃ¡micas**

El scraper utiliza una combinaciÃ³n de variables hardcodeadas y dinÃ¡micas para las solicitudes GraphQL. AquÃ­ se explica cada tipo:

#### **ðŸ”´ Variables CRÃTICAS - Deben ser DinÃ¡micas**
```python
# TOKENS DE AUTENTICACIÃ“N (Obtenidos dinÃ¡micamente del login)
'x-csrftoken': self.tokens['csrf_token']    # âœ… DINÃMICO - Cambia en cada sesiÃ³n
'x-fb-lsd': self.tokens['fb_lsd']           # âœ… DINÃMICO - Cambia en cada sesiÃ³n  
'fb_dtsg': self.tokens['fb_dtsg']           # âœ… DINÃMICO - Cambia en cada sesiÃ³n
'lsd': self.tokens['fb_lsd']                # âœ… DINÃMICO - Cambia en cada sesiÃ³n

# PARÃMETROS DE CONSULTA (DinÃ¡micos segÃºn la operaciÃ³n)
'__req': str(req_type)                      # âœ… DINÃMICO - 3=user, 5=highlights, 7=posts.
                                             # Nota: Si bien en la inspecciÃ³n el __req varÃ­a segÃºn si el query es de user, highlights o posts, la consulta funciona igual con otro valor
'doc_id': doc_id                            # âœ… DINÃMICO - Diferentes para cada tipo
'variables': json.dumps({...})              # âœ… DINÃMICO - SegÃºn user_id y tipo de consultaÂ´


```

#### **ðŸŸ¡ Variables SEMI-CRÃTICAS - DeberÃ­an ser DinÃ¡micas**
```python
# IDENTIFICADORES DE SESIÃ“N (Actualmente hardcodeados, deberÃ­an ser dinÃ¡micos)
'__hs': '20302.HYP:instagram_web_pkg.2.1...0'     # âš ï¸ HARDCODEADO - DeberÃ­a ser dinÃ¡mico
'__rev': '1025456124'                              # âš ï¸ HARDCODEADO - VersiÃ³n de Instagram
'__s': 'azx7hm:v651wx:jjbnoc'                      # âš ï¸ HARDCODEADO - Hash de sesiÃ³n
'__hsi': '7534071026151167731'                     # âš ï¸ HARDCODEADO - ID de sesiÃ³n
'__spin_t': '1754162606'                           # âš ï¸ HARDCODEADO - Timestamp
'jazoest': '26195'                                 # âš ï¸ HARDCODEADO - Token de validaciÃ³n

# HASHES COMPLEJOS (Muy difÃ­ciles de generar dinÃ¡micamente)
'__dyn': '7xeUjG1mxu1syUbFp41twpUnwgU7S6EdF8aUco38w5ux609vCwjE1EE2Cw8G11w6zx62G3i1ywOwa90Fw4Hw9O0M82zxe2GewGw9a361qw8W5U4q09yyES1Twoob82ZwrUdUbGw4mwr86C1mwrd6goK10xKi2qi7E5y4UrwHwcObBK4o16UswFwOwgU'  # Hash de capacidades dinÃ¡micas
'__csr': 'hk4c5sIdiiWeWkp4my9OFliOZZm_GGlbnl8FQW_jqWWXrHZelBAGKQWAUxqjH9mGh9mtyGKcZ2rVtlmVCqfXmWupfAGm8QqUDhEOEnjqVHBGUGcAAx2hpoO4ojS7aDBzqxi5BAhUB5VeV8lyoyAWyQElABzoC4ayu79V8S4Uiw05vaw2bU25o30K1NA80qu584No0zapo1lU3zwwP1uuE0Z-07gVE4e7UKlF2cU1Iodo6Z2UTo1n86dwVg8UJCOwkcw3pc0nCpO08Vk7k0tdw09oK06480aHo'  # Hash de configuraciÃ³n del cliente
'__hsdp', '__hblp', '__sjsp': '[HASHES_LARGOS]'  # Otros hashes de seguridad y configuraciÃ³n
```

#### **ðŸŸ¢ Variables SEGURAS - Pueden estar Hardcodeadas**
```python
# HEADERS HTTP ESTÃNDAR
'accept': '*/*'                                    # âœ… HARDCODEADO - EstÃ¡ndar HTTP
'content-type': 'application/x-www-form-urlencoded' # âœ… HARDCODEADO - Tipo de contenido
'origin': 'https://www.instagram.com'             # âœ… HARDCODEADO - Origen fijo
'referer': 'https://www.instagram.com/'           # âœ… HARDCODEADO - Referencia fija

# INFORMACIÃ“N DEL NAVEGADOR (User Agent)
'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N)...' # âœ… HARDCODEADO - Simula dispositivo
'sec-ch-ua': '"Not)A;Brand";v="8", "Chromium";v="138"...'                  # âœ… HARDCODEADO - Info del navegador
'sec-ch-ua-platform': '"Android"'                 # âœ… HARDCODEADO - Plataforma simulada
'sec-ch-ua-mobile': '?1'                          # âœ… HARDCODEADO - Indica mÃ³vil

# IDENTIFICADORES DE APLICACIÃ“N
'x-ig-app-id': '1217981644879628'                 # âœ… HARDCODEADO - ID de la app de Instagram
'x-asbd-id': '359341'                             # âœ… HARDCODEADO - ID de seguridad
'x-bloks-version-id': '4fd52d0e0985dd463fefe21d18f1609258ecf3c799cc7f12f6c4363b56697384' # âœ… HARDCODEADO

# PARÃMETROS FIJOS
'av': '17841476332219581'                         # âœ… HARDCODEADO - ID de aplicaciÃ³n
'__d': 'www'                                      # âœ… HARDCODEADO - Dominio
'__user': '0'                                     # âœ… HARDCODEADO - Usuario por defecto
'__a': '1'                                        # âœ… HARDCODEADO - ParÃ¡metro de aplicaciÃ³n
'dpr': '2'                                        # âœ… HARDCODEADO - Device Pixel Ratio
'__ccg': 'EXCELLENT'                              # âœ… HARDCODEADO - Calidad de conexiÃ³n
'__spin_r': '1025456124'                          # âœ… HARDCODEADO - VersiÃ³n de Spin
'__spin_b': 'trunk'                               # âœ… HARDCODEADO - Branch de Spin
'__comet_req': '7'                                # âœ… HARDCODEADO - VersiÃ³n de Comet
'fb_api_caller_class': 'RelayModern'              # âœ… HARDCODEADO - Clase de API
'server_timestamps': 'true'                      # âœ… HARDCODEADO - Timestamps del servidor
```

#### **ðŸ”’ Doc IDs Hardcodeados (CRÃTICOS)**
```python
DOC_IDS = {
    'user': '24059491867034637',      # âš ï¸ CRÃTICO - Puede cambiar con actualizaciones
    'highlights': '9814547265267853', # âš ï¸ CRÃTICO - Puede cambiar con actualizaciones  
    'posts': '24312092678414792'      # âš ï¸ CRÃTICO - Puede cambiar con actualizaciones
}
```

#### **ðŸ“Š Resumen de Criticidad**

| Tipo | Riesgo | Estado | AcciÃ³n |
|------|--------|--------|--------|
| ðŸ”´ **Tokens de autenticaciÃ³n** | Alto | âœ… DinÃ¡micos | Funcionan correctamente |
| ðŸŸ¡ **Hashes de sesiÃ³n** | Medio | âš ï¸ Hardcodeados | Actualizar si fallan |
| ðŸŸ¢ **Headers HTTP estÃ¡ndar** | Bajo | âœ… Hardcodeados | No requieren cambios |
| ðŸ”’ **Doc IDs** | Alto | âš ï¸ Hardcodeados | Monitorear cambios |

#### **ðŸš¨ Variables que Pueden Causar Problemas**

- **Doc IDs**: CrÃ­ticos, pueden cambiar con actualizaciones de Instagram
- **Hashes de sesiÃ³n**: Pueden invalidarse, actualizar si el scraper falla
- **Timestamps/Versiones**: Valores muy antiguos pueden ser rechazados

#### **ðŸ’¡ Recomendaciones**

- **Monitorear errores** para detectar variables obsoletas
- **Actualizar Doc IDs** cuando dejen de funcionar
- **Rotar User Agents** periÃ³dicamente para evitar detecciÃ³n

### ï¿½ **CÃ³mdo Actualizar Variables Hardcodeadas**

Cuando el scraper deje de funcionar, probablemente sea por variables hardcodeadas obsoletas. AquÃ­ se explica cÃ³mo actualizarlas:

#### **1. Obtener Nuevos Doc IDs**
```bash
# Abrir Instagram en el navegador
# DevTools > Network > Filtrar por 'graphql'
# Buscar consultas que devuelvan datos de usuario/posts/highlights
# Copiar el doc_id de cada consulta

# Actualizar en scraper_perfil.py:
self.DOC_IDS = {
    'user': 'NUEVO_DOC_ID_USUARIO',
    'highlights': 'NUEVO_DOC_ID_HIGHLIGHTS', 
    'posts': 'NUEVO_DOC_ID_POSTS'
}
```

#### **2. Actualizar Variables de SesiÃ³n**
```bash
# En DevTools > Network, copiar una solicitud GraphQL exitosa
# Buscar estos valores en los headers/payload:
# - __hs, __rev, __s, __hsi, __spin_t, jazoest
# - __dyn, __csr, __hsdp, __hblp, __sjsp

# Actualizar en el mÃ©todo make_graphql_request()
```

#### **3. SeÃ±ales de Variables Obsoletas**
- **Error 400**: ParÃ¡metros invÃ¡lidos (doc_id o hashes obsoletos)
- **Error 403**: Tokens de autenticaciÃ³n invÃ¡lidos
- **Error 429**: Rate limiting (cambiar User Agent)
- **Respuesta vacÃ­a**: Doc ID incorrecto

#### **4. Herramientas de Debugging**
```python
# Activar modo debug para ver requests completos
scraper = ScraperPerfil(debug_mode=True)

# Ver respuestas completas en archivos debug_response_*.json
```

## ðŸ—„ï¸ Base de Datos

### ðŸŽ¯ **InicializaciÃ³n AutomÃ¡tica con Perfiles Famosos**

El sistema incluye inicializaciÃ³n automÃ¡tica con perfiles listos para scrapear

### **ðŸ—‚ï¸ Estructura de Tablas**

### Tabla `usuarios_unicos`
- `username` - Username del usuario (clave primaria)
- `perfil_inactivo` - Si el perfil no se pudo scrapear
- `nombre_persona` - Nombre real de la persona
- `categoria` - CategorÃ­a si es perfil de negocio
- `perfil_privado` - Si el perfil es privado
- `cantidad_publicaciones` - NÃºmero de posts
- `cantidad_destacadas` - NÃºmero de historias destacadas
- `cantidad_seguidores` - NÃºmero de seguidores
- `cantidad_seguidos` - NÃºmero de seguidos
- `biografia` - BiografÃ­a del perfil
- `links_externos` - URL externa del perfil

### Tabla `media_urls`
- `username` - Username (clave forÃ¡nea)
- `url_media` - URL de la imagen/video
- `tipo_media` - 'post' o 'destacada'
- `subtipo_post` - 'foto', 'reel', 'video' (solo posts)
- `cantidad_likes` - Likes del post
- `cantidad_comentarios` - Comentarios del post

## ðŸ” Sistema de Login

**`login.py` es EL ÃšNICO archivo que maneja la autenticaciÃ³n.** No hay otros archivos de login.

### CaracterÃ­sticas:
- **Login interactivo**: Te pide usuario y contraseÃ±a al ejecutar
- **ContraseÃ±a oculta**: Usa `getpass` para ocultar la contraseÃ±a
- **Guardado opcional**: Puede guardar credenciales en `instagram_credentials.json`
- **Tokens automÃ¡ticos**: Extrae automÃ¡ticamente CSRF, fb_lsd, fb_dtsg
- **Manejo de 2FA**: Soporte para verificaciÃ³n adicional
- **SesiÃ³n completa**: Devuelve sesiÃ³n de `requests` lista para usar

### Uso programÃ¡tico:
```python
from login import get_instagram_session

# Obtener sesiÃ³n autenticada
session, tokens, username = get_instagram_session()
```

## âš™ï¸ ConfiguraciÃ³n

En `config.py`:

```python
# ConfiguraciÃ³n de scraping
SCRAPING_CONFIG = {
    'delay_min': 2,           # Delay mÃ­nimo entre requests
    'delay_max': 6,           # Delay mÃ¡ximo entre requests
    'headless': True,         # Chrome sin ventana visible
    'force_rescrape': False,  # Si re-scrapear perfiles completos
}

# Archivos de salida
OUTPUT_CONFIG = {
    'save_csv': True,         # Si guardar archivo CSV
    'csv_file': 'instagram_profiles.csv',
    'database_file': 'instagram_data.db',
}
```

## ðŸ“Š InformaciÃ³n Detallada por Consola

El nuevo scraper muestra informaciÃ³n completa durante la extracciÃ³n:

### **Datos de Usuario**
```
âœ“ Datos de usuario obtenidos:
   ðŸ‘¤ Nombre: @leomessi
   ðŸ“ BiografÃ­a: Futbolista profesional...
   ðŸ‘¥ Seguidores: 500,000,000
   ðŸ‘¤ Siguiendo: 300
   ðŸ“¸ Posts: 1,000
   ðŸ”’ Privado: No
   ðŸ¢ Negocio: SÃ­
   ðŸ“‚ CategorÃ­a: Athlete
   ðŸ”— Link externo: https://example.com
```

### **Highlights**
```
âœ“ 15 highlights obtenidos
   ðŸ“š Highlights encontrados:
      1. Mundial
      2. Familia
      3. Entrenamientos
      4. Viajes
      5. Celebraciones
      ... y 10 mÃ¡s
```

### **Posts**
```
âœ“ 12 posts obtenidos
   ðŸ“Š EstadÃ­sticas de posts:
      ðŸ“¸ Fotos: 8 | ðŸŽ¥ Videos: 4
      â¤ï¸ Total likes: 15,000,000
      ðŸ’¬ Total comentarios: 250,000
      ðŸ“ˆ Promedio likes: 1,250,000
```

### **Resumen Final**
```
ðŸ“‹ RESUMEN COMPLETO - @leomessi
==================================================
ðŸ‘¥ Seguidores: 500,000,000
ðŸ‘¤ Siguiendo: 300
ðŸ“¸ Posts totales: 1,000
ðŸ“¸ Posts extraÃ­dos: 12
ðŸ“š Highlights: 15
ðŸ”’ Perfil privado: No
ðŸ“‚ CategorÃ­a: Athlete
```

## ðŸ§  LÃ³gica Inteligente

El sistema evita re-scrapear perfiles ya completos:

- **Perfil Completo**: Tiene `cantidad_seguidores`, `cantidad_seguidos` y `cantidad_publicaciones` != NULL
- **Perfil Pendiente**: Le falta alguno de los campos principales
- **Force Rescrape**: Configurar `force_rescrape = True` para re-scrapear todo

## ðŸŽ¯ Flujo de Trabajo Simple

1. **Agregar usuarios:**
   ```bash
   python scraper_perfil.py
   # OpciÃ³n 2 â†’ Ingresar: leomessi,cristiano,nasa
   ```

2. **Scrapear usuarios pendientes:**
   ```bash
   python scraper_perfil.py  
   # OpciÃ³n 1 â†’ Login interactivo â†’ Scraping automÃ¡tico
   ```

3. **Scrapear usuario especÃ­fico:**
   ```bash
   python scraper_perfil.py
   # OpciÃ³n 4 â†’ Ingresar username â†’ Ver datos completos
   ```

4. **Ver estadÃ­sticas:**
   ```bash
   python scraper_perfil.py
   # OpciÃ³n 3 â†’ Ver estadÃ­sticas detalladas de BD
   ```

## ðŸ”§ Uso de la Base de Datos

### Con DB Browser for SQLite (Recomendado)
1. Descargar [DB Browser for SQLite](https://sqlitebrowser.org/)
2. Abrir `instagram_data.db`
3. Ver/editar datos directamente

### Consultas SQL Ãštiles
```sql
-- Ver usuarios con mÃ¡s posts extraÃ­dos
SELECT u.username, u.cantidad_seguidores, COUNT(m.url_media) as posts_extraidos
FROM usuarios_unicos u
LEFT JOIN media_urls m ON u.username = m.username AND m.tipo_media = 'post'
GROUP BY u.username
ORDER BY u.cantidad_seguidores DESC;

-- Ver estadÃ­sticas de engagement
SELECT u.username, 
       AVG(m.cantidad_likes) as promedio_likes,
       AVG(m.cantidad_comentarios) as promedio_comentarios
FROM usuarios_unicos u
JOIN media_urls m ON u.username = m.username
WHERE m.tipo_media = 'post'
GROUP BY u.username
ORDER BY promedio_likes DESC;

-- Ver usuarios con highlights
SELECT u.username, u.cantidad_destacadas, COUNT(m.url_media) as highlights_extraidos
FROM usuarios_unicos u
LEFT JOIN media_urls m ON u.username = m.username AND m.tipo_media = 'destacada'
GROUP BY u.username
HAVING u.cantidad_destacadas > 0
ORDER BY u.cantidad_destacadas DESC;
```

## ðŸ—‚ï¸ Archivos que Puedes Eliminar

### ðŸ§ª **Archivos de Testing/Debug (Seguros para eliminar)**
```bash
# Scripts de debugging
rm debug_*.py
rm test_*.py
rm standalone_debug.py

# Respuestas de ejemplo
rm ejemplo_response_*.json
rm debug_response_*.json

# Herramientas de doc_id (ya no necesarias)
rm find_working_doc_ids.py
rm auto_doc_id_finder.py
rm doc_id_manager.py
rm test_doc_ids.py

# Scripts de testing especÃ­ficos
rm test_format_fix.py
rm test_doc_id_logic.py
rm test_real_user.py
rm test_new_extraction.py
rm test_data_viewer.py
rm debug_now.py
rm debug_problematic_users.py
```

### ðŸ“š **Archivos Legacy (Mantener como referencia)**
```bash
# Mantener por ahora como referencia
# scraper_user_data.py - Scraper original
# query_data_user.py - Prototipo GraphQL
```

## ðŸ”’ Seguridad

- Login interactivo (no credenciales hardcodeadas)
- ContraseÃ±a oculta con `getpass`
- Delays inteligentes entre requests
- Manejo de 2FA y verificaciones adicionales
- Doc IDs hardcodeados (no bÃºsqueda dinÃ¡mica)

## ðŸ“Š Archivos Generados

- `instagram_data.db` - Base de datos SQLite principal (**ignorado por Git**)
- `instagram_profiles.csv` - Archivo CSV (si estÃ¡ habilitado) (**ignorado por Git**)
- `instagram_credentials.json` - Credenciales guardadas (**ignorado por Git**)
```

### **ðŸ”’ Archivos Ignorados por Git**
El `.gitignore` estÃ¡ configurado para ignorar automÃ¡ticamente:

```gitignore
# Credenciales de Instagram (NUNCA subir a Git)
instagram_credentials.json
*credentials*.json
*password*.txt
*login*.json
*auth*.json

# Base de datos (se regenera automÃ¡ticamente)
*.db
*.sqlite
*.sqlite3

# Resultados y archivos temporales
*.csv
debug_response_*.json
temp_*

# Archivos de sesiÃ³n y cookies
session_*
cookies_*
*.session

# Python
__pycache__/
*.pyc
venv/
.venv/

# Logs y debugging
*.log
debug_*.txt

# Selenium drivers
chromedriver*
geckodriver*

# Archivos del sistema
.DS_Store
Thumbs.db
```

### **ðŸ›¡ï¸ Seguridad de Credenciales**
- âœ… **instagram_credentials.json** - Completamente ignorado por Git
- âœ… **ContraseÃ±as** - Nunca se almacenan en cÃ³digo fuente
- âœ… **Tokens de sesiÃ³n** - Solo en memoria durante ejecuciÃ³n
- âœ… **Cookies** - No se guardan en archivos versionados

### **ðŸ“ ConfiguraciÃ³n Manual de Credenciales (Opcional)**
Si prefieres configurar credenciales manualmente:

```bash
# Copiar el archivo de ejemplo
cp instagram_credentials.example.json instagram_credentials.json

# Editar con tus credenciales reales
# IMPORTANTE: instagram_credentials.json estÃ¡ en .gitignore y NUNCA se subirÃ¡ a Git
```

Formato del archivo `instagram_credentials.json`:
```json
{
  "username": "tu_username_real",
  "password": "tu_password_real"
}
```

## ï¿½ *o*Monitoreo y Mantenimiento**

### **ðŸ“Š Indicadores de Salud del Scraper**
```python
# Ejecutar diagnÃ³stico
python scraper_perfil.py
# OpciÃ³n 4 â†’ Probar con un usuario conocido

# SeÃ±ales de que necesita mantenimiento:
# âŒ Error 400: "execution error" â†’ Doc IDs obsoletos
# âŒ Error 403: "Forbidden" â†’ Tokens/hashes obsoletos  
# âŒ Respuestas vacÃ­as â†’ ParÃ¡metros incorrectos
# âŒ Rate limiting â†’ Cambiar User Agent
```

### **ðŸ”„ Frecuencia de ActualizaciÃ³n Recomendada**
- **Doc IDs**: Verificar mensualmente o cuando fallen
- **Hashes de sesiÃ³n**: Actualizar cada 2-3 meses
- **User Agent**: Rotar semanalmente
- **Tokens de autenticaciÃ³n**: Se renuevan automÃ¡ticamente

### **ðŸ“ˆ OptimizaciÃ³n de Rendimiento**
```python
# Configurar delays apropiados en config.py
SCRAPING_CONFIG = {
    'delay_min': 2,    # MÃ­nimo 2 segundos entre requests
    'delay_max': 6,    # MÃ¡ximo 6 segundos para evitar detecciÃ³n
}

# Monitorear tasa de Ã©xito
# > 90% Ã©xito = ConfiguraciÃ³n Ã³ptima
# < 70% Ã©xito = Necesita mantenimiento
```

## ðŸš¨ Consideraciones

- Respetar tÃ©rminos de servicio de Instagram
- Uso moderado para evitar detecciÃ³n
- Los tokens expiran, renovar sesiÃ³n periÃ³dicamente
- **Variables hardcodeadas requieren mantenimiento periÃ³dico**
- **Doc IDs son crÃ­ticos y pueden cambiar sin aviso**
- **Monitorear regularmente la tasa de Ã©xito del scraper**

---




